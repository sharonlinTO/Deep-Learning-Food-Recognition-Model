{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"V6-Dataset-Extraction.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"j4w6FlXL1EAU","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import os\n","import tqdm\n","\n","path = \"/content/drive/My Drive/APS360 Project/v6-dataset/\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-cwSi64l122o","colab_type":"code","outputId":"c96ece4f-73ce-453f-9f7b-2bedb0014809","executionInfo":{"status":"ok","timestamp":1584672515795,"user_tz":240,"elapsed":17931,"user":{"displayName":"Sharon Lin","photoUrl":"","userId":"12349125637223942905"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aYEXqYa21tMi","colab_type":"code","colab":{}},"source":["# Extract image ID from annotation file\n","def extract_img_id():\n","    extracted_class = pd.read_csv(os.path.join(path,'class-descriptions.csv'))\n","   \n","    data = ['test', 'validation', 'train']\n","\n","    for i in data:\n","        extracted = {}\n","        extracted['ImageID'], extracted['Class_ID'], extracted['Class_Description'] = [],[],[]\n","        extracted['XMin'], extracted['XMax'], extracted['YMin'], extracted['YMax'] = [],[],[],[]\n","        file_path = os.path.join(path, i+'-annotations-bbox.csv')\n","        image_id_csv = pd.read_csv(file_path,\n","                                   usecols=['ImageID','LabelName','XMin','XMax','YMin','YMax'])\n","        bar = tqdm.tqdm(total=len(image_id_csv.ImageID),desc='EXTRACTING',position=0)\n","\n","        for j in range(len(image_id_csv.ImageID)):\n","            bar.update(1)\n","            if image_id_csv.LabelName[j] in extracted_class['Class_ID'].values:\n","                idx_in_data = extracted_class.Class_ID[extracted_class.Class_ID==image_id_csv.LabelName[j]].index.tolist()[0]\n","                extracted['ImageID'].append(image_id_csv.ImageID[j])\n","                extracted['Class_ID'].append(extracted_class.Class_ID[idx_in_data])\n","                extracted['Class_Description'].append(extracted_class.Class_Description[idx_in_data])\n","                extracted['XMin'].append(image_id_csv.XMin[j])\n","                extracted['XMax'].append(image_id_csv.XMax[j])\n","                extracted['YMin'].append(image_id_csv.YMin[j])\n","                extracted['YMax'].append(image_id_csv.YMax[j])\n","        \n","        # Export file\n","        export_csv = pd.DataFrame(extracted).to_csv(os.path.join(path, i+'.csv'),index=None,header=True)\n","\n","extract_img_id()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lhsmUgX5NdIt","colab_type":"code","colab":{}},"source":["# Extracted all image URLs based on image ID\n","def id_to_url():\n","    extracted_class = pd.read_csv(os.path.join(path,'class-descriptions.csv'))\n","   \n","    data = ['test', 'train', 'validation']\n","\n","    for i in data:\n","        class_id_data = pd.read_csv(os.path.join(path,i+'.csv'))\n","        extracted_image_url = {}\n","\n","        extracted_image_url['ImageID'], extracted_image_url['Image_title'], extracted_image_url['Class_ID'], extracted_image_url['Class_Description'] = [],[],[],[]\n","        extracted_image_url['XMin'], extracted_image_url['XMax'], extracted_image_url['YMin'], extracted_image_url['YMax'] = [],[],[],[]\n","        extracted_image_url['Image_url'] = []\n","        file_path = os.path.join(path, i+'-annotations-bbox.csv')\n","        image_url_data = pd.read_csv(os.path.join(path, i+'-images-with-rotation.csv'), usecols=['ImageID','Title','Thumbnail300KURL'])\n","        bar = tqdm.tqdm(total=len(image_url_data.ImageID),desc='EXTRACTING',position=0)\n","        for j in range(len(image_url_data.ImageID)):\n","            bar.update(1)\n","            if (image_url_data.ImageID[j] in class_id_data['ImageID'].values):\n","                idx_in_data = class_id_data.ImageID[class_id_data.ImageID==image_url_data.ImageID[j]].index.tolist()[0]\n","                extracted_image_url['ImageID'].append(image_url_data.ImageID[j])\n","                extracted_image_url['Image_title'].append(image_url_data.Title[j])\n","                extracted_image_url['Class_ID'].append(class_id_data.Class_ID[idx_in_data])\n","                extracted_image_url['Class_Description'].append(class_id_data.Class_Description[idx_in_data])\n","                extracted_image_url['Image_url'].append(image_url_data.Thumbnail300KURL[j])\n","                extracted_image_url['XMin'].append(class_id_data.XMin[idx_in_data])\n","                extracted_image_url['XMax'].append(class_id_data.XMax[idx_in_data])\n","                extracted_image_url['YMin'].append(class_id_data.YMin[idx_in_data])\n","                extracted_image_url['YMax'].append(class_id_data.YMax[idx_in_data])\n","                \n","        # Export file\n","        export_csv = pd.DataFrame(extracted_image_url).to_csv(os.path.join(path, i+'-id.csv'),index=None,header=True)\n","\n","id_to_url()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JHQH4V1KNdf5","colab_type":"code","colab":{}},"source":["# Download the images\n","import urllib\n","\n","def download():\n","    img_url_data = pd.read_csv(os.path.join(path,'train-id.csv'))\n","    bar = tqdm.tqdm(total=len(img_url_data.Image_url),desc='Downloading',position=0)\n","    for j in range(len(img_url_data.Image_url)):\n","        bar.update(1)\n","        img_name = img_url_data.Class_Description[j] + '-' + img_url_data.ImageID[j] + '.png'\n","        file_name = os.path.join(path,'train',img_name)\n","        url = img_url_data.Image_url[j]\n","        try:\n","            print('Downloading from ' + url)\n","            urllib.request.urlretrieve(url,file_name)\n","            print('Success\\n\\n')\n","        except:\n","            print('Failed\\n\\n')\n","\n","download()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xPyXoCRxvt0g","colab_type":"code","outputId":"f3a60343-3598-4ad1-d309-086b66e7b962","executionInfo":{"status":"ok","timestamp":1584675061362,"user_tz":240,"elapsed":14455,"user":{"displayName":"Sharon Lin","photoUrl":"","userId":"12349125637223942905"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["def cleanTrainAnnotationFile():\n","\n","    # Get a list of all the files in a directory (allImages)\n","    # Within the file, check if the csv entry is in the file directory\n","        # If it is, add to dict: | path to image | class description | bbox |\n","    # After going through all the images, store dict into a csv\n","\n","    allImages1 = list()\n","    file_path = os.path.join(path, 'train-1')\n","    for f in os.listdir(file_path):\n","        allImages1.append(f)\n","\n","    allImages2 = list()\n","    file_path = os.path.join(path, 'train-2')\n","    for f in os.listdir(file_path):\n","        allImages2.append(f)\n","\n","    allImages3 = list()\n","    file_path = os.path.join(path, 'train-3')\n","    for f in os.listdir(file_path):\n","        allImages3.append(f)\n","\n","    print(len(allImages1))\n","    print(len(allImages2))\n","    print(len(allImages3))\n","    print(len(allImages1) + len(allImages2) + len(allImages3))\n","\n","    # Get the path to the CSV file\n","    headers = pd.read_csv(os.path.join(path, 'train-id.csv'))\n","\n","    # This is the dictionary we will use\n","    extracted = {}\n","\n","    extracted['filePath'], extracted['Class_Description'] = [],[],\n","    extracted['XMin'], extracted['XMax'], extracted['YMin'], extracted['YMax'] = [],[],[],[]\n","\n","    for j in range(len(headers.ImageID)):\n","\n","        # Get the file name\n","        fileName = headers.Class_Description[j]+'-'+headers.ImageID[j]+'.png'\n","\n","        if fileName in allImages1:\n","            extracted['filePath'].append(os.path.join(path, 'train-1', fileName))\n","            extracted['Class_Description'].append(headers.Class_Description[j])\n","            extracted['XMin'].append(headers.XMin[j])\n","            extracted['XMax'].append(headers.XMax[j])\n","            extracted['YMin'].append(headers.YMin[j])\n","            extracted['YMax'].append(headers.YMax[j])\n","            \n","        elif fileName in allImages2:\n","            extracted['filePath'].append(os.path.join(path, 'train-2', fileName))\n","            extracted['Class_Description'].append(headers.Class_Description[j])\n","            extracted['XMin'].append(headers.XMin[j])\n","            extracted['XMax'].append(headers.XMax[j])\n","            extracted['YMin'].append(headers.YMin[j])\n","            extracted['YMax'].append(headers.YMax[j])\n","\n","        elif fileName in allImages3:\n","            extracted['filePath'].append(os.path.join(path, 'train-3', fileName))\n","            extracted['Class_Description'].append(headers.Class_Description[j])\n","            extracted['XMin'].append(headers.XMin[j])\n","            extracted['XMax'].append(headers.XMax[j])\n","            extracted['YMin'].append(headers.YMin[j])\n","            extracted['YMax'].append(headers.YMax[j])\n","\n","    # Export file\n","    export_csv = pd.DataFrame(extracted).to_csv(os.path.join(path, 'clean-train-id.csv'), index=None, header=True)\n","    print(len(extracted['filePath']))\n","    print(len(extracted['Class_Description']))\n","    print(len(extracted['XMin']))\n","    print(len(extracted['XMax']))\n","    print(len(extracted['YMin']))\n","    print(len(extracted['YMax']))\n","\n","cleanTrainAnnotationFile()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["17159\n","9904\n","6019\n","33082\n","33082\n","33082\n","33082\n","33082\n","33082\n","33082\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C3jsKswW_ez0","colab_type":"code","outputId":"bc539fe1-7e1c-451d-e9c6-29d4ae4f251f","executionInfo":{"status":"ok","timestamp":1584675668331,"user_tz":240,"elapsed":810,"user":{"displayName":"Sharon Lin","photoUrl":"","userId":"12349125637223942905"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["def cleanValAnnotationFile():\n","\n","    # Get a list of all the files in a directory (allImages)\n","    # Within the file, check if the csv entry is in the file directory\n","        # If it is, add to dict: | path to image | class description | bbox |\n","    # After going through all the images, store dict into a csv\n","\n","    allImages1 = list()\n","    file_path = os.path.join(path, 'validation')\n","    for f in os.listdir(file_path):\n","        allImages1.append(f)\n","\n","    print(len(allImages1))\n","\n","    # Get the path to the CSV file\n","    headers = pd.read_csv(os.path.join(path, 'validation-id.csv'))\n","\n","    # This is the dictionary we will use\n","    extracted = {}\n","\n","    extracted['filePath'], extracted['Class_Description'] = [],[],\n","    extracted['XMin'], extracted['XMax'], extracted['YMin'], extracted['YMax'] = [],[],[],[]\n","\n","    for j in range(len(headers.ImageID)):\n","\n","        # Get the file name\n","        fileName = headers.Class_Description[j]+'-'+headers.ImageID[j]+'.png'\n","\n","        if fileName in allImages1:\n","            extracted['filePath'].append(os.path.join(path, 'validation', fileName))\n","            extracted['Class_Description'].append(headers.Class_Description[j])\n","            extracted['XMin'].append(headers.XMin[j])\n","            extracted['XMax'].append(headers.XMax[j])\n","            extracted['YMin'].append(headers.YMin[j])\n","            extracted['YMax'].append(headers.YMax[j])\n","\n","    # Export file\n","    export_csv = pd.DataFrame(extracted).to_csv(os.path.join(path, 'clean-validation-id.csv'), index=None, header=True)\n","    print(\"\\n\")\n","    print(len(extracted['filePath']))\n","    print(len(extracted['Class_Description']))\n","    print(len(extracted['XMin']))\n","    print(len(extracted['XMax']))\n","    print(len(extracted['YMin']))\n","    print(len(extracted['YMax']))\n","\n","cleanValAnnotationFile()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2303\n","\n","\n","2303\n","2303\n","2303\n","2303\n","2303\n","2303\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"llbzoO87A8Jl","colab_type":"code","outputId":"d63c3bca-7f94-4ba3-8ff9-bdbda64ae272","executionInfo":{"status":"ok","timestamp":1584675552048,"user_tz":240,"elapsed":1647,"user":{"displayName":"Sharon Lin","photoUrl":"","userId":"12349125637223942905"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["def cleanTestAnnotationFile():\n","\n","    # Get a list of all the files in a directory (allImages)\n","    # Within the file, check if the csv entry is in the file directory\n","        # If it is, add to dict: | path to image | class description | bbox |\n","    # After going through all the images, store dict into a csv\n","\n","    allImages1 = list()\n","    file_path = os.path.join(path, 'test')\n","    for f in os.listdir(file_path):\n","        allImages1.append(f)\n","\n","    print(len(allImages1))\n","\n","    # Get the path to the CSV file\n","    headers = pd.read_csv(os.path.join(path, 'test-id.csv'))\n","\n","    # This is the dictionary we will use\n","    extracted = {}\n","\n","    extracted['filePath'], extracted['Class_Description'] = [],[],\n","    extracted['XMin'], extracted['XMax'], extracted['YMin'], extracted['YMax'] = [],[],[],[]\n","\n","    for j in range(len(headers.ImageID)):\n","\n","        # Get the file name\n","        fileName = headers.Class_Description[j]+'-'+headers.ImageID[j]+'.png'\n","\n","        if fileName in allImages1:\n","            extracted['filePath'].append(os.path.join(path, 'test', fileName))\n","            extracted['Class_Description'].append(headers.Class_Description[j])\n","            extracted['XMin'].append(headers.XMin[j])\n","            extracted['XMax'].append(headers.XMax[j])\n","            extracted['YMin'].append(headers.YMin[j])\n","            extracted['YMax'].append(headers.YMax[j])\n","\n","    # Export file\n","    export_csv = pd.DataFrame(extracted).to_csv(os.path.join(path, 'clean-test-id.csv'), index=None, header=True)\n","    print(\"\\n\")\n","    print(len(extracted['filePath']))\n","    print(len(extracted['Class_Description']))\n","    print(len(extracted['XMin']))\n","    print(len(extracted['XMax']))\n","    print(len(extracted['YMin']))\n","    print(len(extracted['YMax']))\n","\n","cleanTestAnnotationFile()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["6873\n","\n","\n","6873\n","6873\n","6873\n","6873\n","6873\n","6873\n"],"name":"stdout"}]}]}