{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Faster-RCNN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"_NmdOBASd0gk","colab_type":"code","outputId":"09fff7f5-7016-4010-8e00-221f6741c0ec","executionInfo":{"status":"ok","timestamp":1585685886165,"user_tz":240,"elapsed":581,"user":{"displayName":"Sharon Lin","photoUrl":"","userId":"12349125637223942905"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WKP7aKE3egO0","colab_type":"code","colab":{}},"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import random\n","import tqdm\n","import time\n","from PIL import Image\n","from google.colab.patches import cv2_imshow\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torchvision.transforms as transforms\n","import torchvision.models\n","from torchvision.models.detection.rpn import AnchorGenerator\n","from torchvision.models.detection import FasterRCNN\n","\n","path = \"/content/drive/My Drive/APS360 Project/v6-dataset/\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W3qefCpWfCpF","colab_type":"code","outputId":"39725582-d881-4bdf-af4f-9b4822d381ac","executionInfo":{"status":"ok","timestamp":1585685887307,"user_tz":240,"elapsed":1641,"user":{"displayName":"Sharon Lin","photoUrl":"","userId":"12349125637223942905"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["if torch.cuda.is_available():\n","    print(\"CUDA activated\")\n","    use_cuda = True\n","    device = torch.device(\"cuda\")\n","    \n","else:\n","    print(\"Using CPU\")\n","    device = \"cpu\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["CUDA activated\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dYPIuNflfQBS","colab_type":"code","outputId":"365e18d9-b7ac-4a90-dbeb-7030a0d52844","executionInfo":{"status":"ok","timestamp":1585685888402,"user_tz":240,"elapsed":2705,"user":{"displayName":"Sharon Lin","photoUrl":"","userId":"12349125637223942905"}},"colab":{"base_uri":"https://localhost:8080/","height":302}},"source":["# Get the type of GPU\n","\n","!nvidia-smi"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tue Mar 31 20:18:06 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P0    28W / 250W |     10MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kjpkkOyefgUc","colab_type":"code","colab":{}},"source":["# These ae the classes we will be training in our model\n","\n","classes = {\"Apple\":0,\n","           \"Bagel\":1,\n","           \"Banana\":2,\n","           \"Bread\":3,\n","           \"Broccoli\":4,\n","           \"Burrito\":5,\n","           \"Carrot\":6,\n","           \"Cheese\":7,\n","           \"Coffee\":8,\n","           \"Cookie\":9,\n","           \"Cucumber\":10,\n","           \"Egg (Food)\":11,\n","           \"French fries\":12,\n","           \"Grape\":13,\n","           \"Hamburger\":14,\n","           \"Hot dog\":15,\n","           \"Juice\":16,\n","           \"Lemon\":17,\n","           \"Lobster\":18,\n","           \"Muffin\":19,\n","           \"Orange\":20,\n","           \"Pancake\":21,\n","           \"Pasta\":22,\n","           \"Pear\":23,\n","           \"Pizza\":24,\n","           \"Potato\":25,\n","           \"Salad\":26,\n","           \"Sandwich\":27,\n","           \"Strawberry\":28,\n","           \"Taco\":29,\n","           \"Tomato\":30,\n","           \"Waffle\":31}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CQVdMcgFqYSH","colab_type":"code","outputId":"8ce2f7a0-0413-4931-b601-7b8fefd381e9","executionInfo":{"status":"ok","timestamp":1585685888404,"user_tz":240,"elapsed":2648,"user":{"displayName":"Sharon Lin","photoUrl":"","userId":"12349125637223942905"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Write the dataloaders\n","# filePath | Class_Description | XMin | XMax | YMin | YMax\n","\n","headers = pd.read_csv(os.path.join(path, 'clean-train-id.csv'))\n","headers = headers.sample(frac=1).head(5)\n","len(headers.filePath)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"9Z3xZXWziESB","colab_type":"code","colab":{}},"source":["def dataloader(filePath='clean-train-id.csv', batch_size=8, normalize=True):\n","    # Load default width\n","    widthScale = 300\n","    \n","    # Load csv and shuffle\n","    headers = pd.read_csv(os.path.join(path, filePath))\n","    headers = headers.sample(frac=1)\n","    transform = transforms.ToTensor()\n","    if normalize:\n","        transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","    \n","    # Make tensor of images, (labels and bbox)\n","    for i in range(0, len(headers.filePath), batch_size):\n","        imgs, label = [], []\n","        \n","        for j in range(batch_size):\n","\n","            # Old image\n","            if i+j >= len(headers.filePath):\n","                break\n","\n","            imgOG = Image.open(headers.filePath[i+j]).convert('RGB')\n","            wpercent = (widthScale/float(imgOG.size[0]))\n","            hsize = int((float(imgOG.size[1])*wpercent))\n","            # display(imgOG)\n","\n","            # New image\n","            img = imgOG.resize((widthScale, hsize), Image.ANTIALIAS)\n","            # display(img)\n","            w, h = img.size\n","            img = transform(img).cuda()\n","            \n","            # print(f\"Old: {imgOG.size}\")\n","            # print(f\"New: ({w}, {h})\")\n","            # print(f\"Shape: {img.shape}\")\n","            # print('=====================')\n","            imgs.append(img)\n","\n","            # Add labels to the dictionary\n","            boxes_dict = {}\n","            boxes_dict['boxes'] = torch.tensor([[headers.XMin[i+j] * w, \n","                                                 headers.YMin[i+j] * h, \n","                                                 headers.XMax[i+j] * w, \n","                                                 headers.YMax[i+j] * h]]).cuda()\n","            boxes_dict['labels'] = torch.tensor([classes[headers.Class_Description[i+j]]]).cuda()\n","\n","            label.append(boxes_dict)\n","        \n","        yield imgs, label"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e0Bs0R5fLlYZ","colab_type":"code","colab":{}},"source":["def sampleDataSet(filePath='clean-train-id.csv', batch_size=8, normalize=True):\n","    # Load default width\n","    widthScale = 250\n","    \n","    # Load csv and shuffle\n","    headers = pd.read_csv(os.path.join(path, filePath))\n","    headers = headers.sample(frac=1)\n","    length = int(0.05 * len(headers.filePath))\n","    print(f\"LENGTH: {length}\")\n","    transform = transforms.ToTensor()\n","    \n","    if normalize:\n","        transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","    \n","    for i in range(0, length, batch_size):\n","        imgs, label = [], []\n","\n","        for j in range(batch_size):\n","            # Old image\n","            # Old image\n","\n","            if i+j >= length:\n","                break\n","\n","            imgOG = Image.open(headers.filePath[i+j]).convert('RGB')\n","            wpercent = (widthScale/float(imgOG.size[0]))\n","            hsize = int((float(imgOG.size[1])*wpercent))\n","            # display(imgOG)\n","\n","            # New image\n","            img = imgOG.resize((widthScale, hsize), Image.ANTIALIAS)\n","            # display(img)\n","            w, h = img.size\n","            img = transform(img).cuda()\n","            \n","            imgs.append(img)\n","\n","            # Add labels to the dictionary\n","            boxes_dict = {}\n","            boxes_dict['boxes'] = torch.tensor([[headers.XMin[i+j] * w, \n","                                                 headers.YMin[i+j] * h, \n","                                                 headers.XMax[i+j] * w, \n","                                                 headers.YMax[i+j] * h]]).cuda()\n","            boxes_dict['labels'] = torch.tensor([classes[headers.Class_Description[i+j]]]).cuda()\n","\n","            label.append(boxes_dict)\n","        \n","        yield imgs, label"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zy3Sxjmv0Mtz","colab_type":"code","colab":{}},"source":["def get_train_accuracy(model,box_labels,img):\n","    model = model.cuda(0)\n","    model = model.eval()\n","    out = model(img)\n","    total = 0\n","    correct = 0\n","\n","    with torch.no_grad():\n","        for i in range(len(out)):\n","            if out[i]['labels'].tolist()!=[]:\n","                find_box = 0\n","\n","                if out[i]['labels'].tolist()[find_box]==box_labels[i]['labels'].tolist()[0]:\n","                    correct += 1\n","\n","                resize_box = np.array(out[i]['boxes'][find_box].cuda(0).tolist())*0.375\n","                print(('\\t\\tPredicted {},{} |  expected {}, {}').format(out[i]['labels'][find_box].cuda(0),resize_box,box_labels[i]['labels'][0],box_labels[i]['boxes'][0].tolist()))\n","            else:\n","                print(('\\t\\tPredicted NONE |  expected {}, {}').format(box_labels[i]['labels'][0],box_labels[i]['boxes'][0].tolist()))\n","            total += 1\n","\n","    model = model.train()\n","    return correct/total\n","\n","def get_train_acc_end(model, batch_size=6):\n","    s_losses = []\n","    tr_idx = 0\n","    correct = 0\n","    total = 0\n","    \n","    with torch.no_grad():\n","        imported = sampleDataSet(filePath='clean-train-id.csv', batch_size=batch_size, normalize=True)\n","        \n","        for img, box in imported:\n","            box_cp = box[0].copy()\n","            model = model.eval()\n","\n","            if model(img)[0]['labels'].tolist()!=[]:\n","                predict = model(img)[0]\n","                find_idx = 0\n","\n","                for each in range(predict['labels'].shape[0]):\n","                    # print(predict['labels'].tolist())\n","                    # print(box_cp['labels'].tolist())\n","\n","                    if predict['labels'].tolist()[each]==box_cp['labels'].tolist()[0]:\n","                        correct += 1\n","                        find_idx = each\n","                        break\n","                        \n","                out = predict['labels'][find_idx]\n","                resize_box = np.array(predict['boxes'][find_idx].tolist())*0.375 \n","                print(('\\t\\tPredicted {},{} | Expected {}, {}').format(out, resize_box, box_cp['labels'][0], box_cp['boxes'][0].tolist()))\n","            else:\n","                print(('\\t\\tPredicted NONE |  Expected {}, {}').format(box_cp['labels'][0], box_cp['boxes'][0].tolist()))\n","\n","            total += 1\n","            print (('\\tProcessing iteration {} | Training Acc: {}').format(tr_idx, correct/total))\n","            tr_idx += 1\n","    \n","    return correct/total\n","    \n","def get_val_loss_acc(val_model, batch_size=4):\n","    s_losses = []\n","    val_idx = 0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        val_model = val_model.train()    \n","        imported = dataloader(filePath='clean-validation-id.csv', batch_size=batch_size, normalize=True)\n","        \n","        for img, box in imported:\n","            box_cp = box[0].copy()\n","            loss_dict = val_model(img,box)\n","            losses = sum(loss for loss in loss_dict.values())\n","            s_losses.append(losses/batch_size)\n","            del loss_dict\n","            val_model = val_model.eval()\n","\n","            if val_model(img)[0]['labels'].tolist()!=[]:\n","                predict =  val_model(img)[0]\n","                find_idx = 0\n","\n","                for each in range(predict['labels'].shape[0]):\n","                    # print(predict['labels'].tolist())\n","                    # print(box_cp['labels'].tolist())\n","\n","                    if predict['labels'].tolist()[each]==box_cp['labels'].tolist()[0]:\n","                        correct += 1\n","                        find_idx = each\n","                        break\n","                        \n","                out = predict['labels'][find_idx]\n","                resize_box = np.array(predict['boxes'][find_idx].tolist())*0.375 \n","                print(('\\t\\tPredicted {},{} | Expected {}, {}').format(out,resize_box,box_cp['labels'][0],box_cp['boxes'][0].tolist()))\n","            else:\n","                print(('\\t\\tPredicted NONE |  Expected {}, {}').format(box_cp['labels'][0],box_cp['boxes'][0].tolist()))\n","\n","            total += 1\n","            print (('\\tProcessing iteration {}... Val Loss: {} | Val Acc: {}').format(val_idx,s_losses[-1],correct/total))\n","            val_idx += 1\n","            val_model = val_model.train()\n","\n","    return [sum(s_losses)/len(s_losses), correct/total]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rIdLx_IbJO1A","colab_type":"code","colab":{}},"source":["# Training Code (from a checkpoint)\n","def train_net_continue(model, batch_size=4, num_epochs=50, learning_rate=0.0001,\n","                      weight_decay=0.0002, lr_decay=4, ep=0, ck=0):\n","    \n","    model_path = f\"bs{batch_size}_lr{learning_rate}_epoch{ep}_checkpoint_{ck}\"\n","    checkpoint = torch.load(os.path.join(path, 'faster-rcnn-checkpoints/')+ model_path+'.pth')\n","\n","    start_time = time.time()\n","    torch.manual_seed(1000)\n","    params = [p for p in model.parameters() if p.requires_grad]\n","    optimizer = optim.Adam(params, lr=learning_rate, weight_decay=weight_decay)\n","\n","    # Load states from the checkpoint\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    checkpoint_num = checkpoint['checkpoint_num']+1\n","    model = model.cuda(0)\n","    model = model.train()\n","    start_time = time.time()\n","\n","    # Load values from the checkpoint\n","    saved_x = checkpoint['saved_x']\n","    saved_train_losses = checkpoint['saved_train_loss']\n","    saved_val_losses = checkpoint['saved_val_loss']\n","    train_acc = checkpoint['train_acc']\n","    val_acc = checkpoint['val_acc']\n","\n","    del checkpoint\n","\n","    # training\n","    saved_idx = 0                                                                        \n","    if saved_x!=[]:\n","        saved_idx = saved_x[-1]+1 \n","\n","    iter_acc = []\n","    iter_loss = []\n","\n","    print(f\"\\nval_acc: {val_acc[-1]}\\nsaved_idx: {saved_idx}\")\n","\n","    for epoch in range(ep+1, num_epochs):\n","        file_idx = 0\n","        print(f\"This is epoch: {epoch}\")\n","        bar = tqdm.tqdm(total=31236//batch_size,desc='TRAINING',position=0)\n","        i = 0\n","        data = dataloader(batch_size=batch_size)\n","        correct = 0\n","\n","        for batch_img, batch_box in data:\n","            bar.update(1)\n","            batch_box_cp = batch_box.copy()\n","            loss_dict = model(batch_img, batch_box)\n","            losses = sum(loss for loss in loss_dict.values())\n","            optimizer.zero_grad()\n","            losses.backward()\n","            optimizer.step()\n","            iter_loss.append(float(losses)/batch_size)\n","            i += 1\n","            print (('{} Processing iteration {}... Train Loss: {}').format(file_idx,i,iter_loss[-1]))\n","\n","            file_idx += 1\n","            if file_idx%1000==0:\n","                saved_x.append(saved_idx)\n","                saved_idx += 1\n","                saved_train_losses.append(sum(iter_loss)/len(iter_loss))\n","                train_acc.append(get_train_acc_end(model, batch_size=6))\n","                [current_val_loss,current_val_acc] = get_val_loss_acc(model, batch_size=6)\n","                saved_val_losses.append(current_val_loss)\n","\n","                print ('-------------------------------------------------------------------------------------------')\n","                iter_loss = []\n","                val_acc.append(current_val_acc)  # compute validation accuracy\n","\n","                print((\"Epoch {} | Train Acc: {} | Validation acc: {}\").format(epoch + 1, train_acc[-1], val_acc[-1]))\n","                print ('-------------------------------------------------------------------------------------------')\n","                model_path = \"bs{0}_lr{1}_epoch{2}_checkpoint_{3}\".format(batch_size,learning_rate,epoch,checkpoint_num)\n","                torch.save({\n","                    'checkpoint_num': checkpoint_num,\n","                    'epoch': epoch,\n","                    'model_state_dict': model.state_dict(),\n","                    'optimizer_state_dict': optimizer.state_dict(),\n","                    'saved_train_loss': saved_train_losses,\n","                    'saved_val_loss':saved_val_losses,\n","                    'saved_x':saved_x,\n","                    'train_acc':train_acc,\n","                    'val_acc':val_acc\n","                    }, os.path.join(path, 'faster-rcnn-checkpoints/')+ model_path+'.pth')\n","\n","                checkpoint_num += 1\n","\n","    # plotting\n","    plt.title(\"Training vs Validation Loss\")\n","    plt.plot(saved_x, saved_train_losses, label=\"Train\")\n","    plt.plot(saved_x, saved_val_losses, label='Validation')\n","    plt.xlabel(\"Iterations\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend(loc='best')\n","    plt.show()\n","\n","    plt.title(\"Training vs Validation Accuracy\")\n","    plt.plot(saved_x, val_acc, label=\"Validation\")\n","    plt.xlabel(\"Iterations\")\n","    plt.ylabel(\"Training Accuracy\")\n","    plt.legend(loc='best')\n","    plt.show()\n","\n","    end_time = time.time()\n","    duration = end_time - start_time\n","\n","    if len(val_acc) != 0:\n","        print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n","\n","    print (\"Trained Duration: {} seconds\".format(duration))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kU6B2RU3orsu","colab_type":"code","colab":{}},"source":["anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 200),),aspect_ratios=((0.5, 1.0, 2.0),))\n","backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n","backbone.out_channels = 1280\n","roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],output_size=7,sampling_ratio=2)\n","rcnn1 = FasterRCNN(backbone,num_classes=32,rpn_anchor_generator=anchor_generator,box_roi_pool=roi_pooler).cuda(0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zMPVtjBniA8z","colab_type":"code","outputId":"79213149-9352-458f-d4a5-40bb7b9f5576","executionInfo":{"status":"error","timestamp":1585679702872,"user_tz":240,"elapsed":3058409,"user":{"displayName":"Sharon Lin","photoUrl":"","userId":"12349125637223942905"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1quQwpd7eMhQZFRNtTQN8KXAV_24n6TES"}},"source":["train_net_continue(rcnn1, batch_size=6, num_epochs=10, learning_rate=0.0001, weight_decay=0.0001, ep=3, ck=17)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}